{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9177835,"sourceType":"datasetVersion","datasetId":5546853}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kasinadhsarma1/medbot?scriptVersionId=240098808\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install transformers datasets accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:18:34.535682Z","iopub.execute_input":"2025-05-16T14:18:34.536014Z","iopub.status.idle":"2025-05-16T14:18:39.379552Z","shell.execute_reply.started":"2025-05-16T14:18:34.535968Z","shell.execute_reply":"2025-05-16T14:18:39.378356Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:18:39.381069Z","iopub.execute_input":"2025-05-16T14:18:39.38139Z","iopub.status.idle":"2025-05-16T14:19:04.479156Z","shell.execute_reply.started":"2025-05-16T14:18:39.381366Z","shell.execute_reply":"2025-05-16T14:19:04.478219Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# data loading\nimport pandas as pd\ndf = pd.read_csv('/kaggle/input/ai-medical-chatbot/ai-medical-chatbot.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:19:04.480262Z","iopub.execute_input":"2025-05-16T14:19:04.480846Z","iopub.status.idle":"2025-05-16T14:19:10.137046Z","shell.execute_reply.started":"2025-05-16T14:19:04.480823Z","shell.execute_reply":"2025-05-16T14:19:10.136201Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                         Description  \\\n0      Q. What does abutment of the nerve root mean?   \n1  Q. What should I do to reduce my weight gained...   \n2  Q. I have started to get lots of acne on my fa...   \n3  Q. Why do I have uncomfortable feeling between...   \n4  Q. My symptoms after intercourse threatns me e...   \n\n                                             Patient  \\\n0  Hi doctor,I am just wondering what is abutting...   \n1  Hi doctor, I am a 22-year-old female who was d...   \n2  Hi doctor! I used to have clear skin but since...   \n3  Hello doctor,I am having an uncomfortable feel...   \n4  Hello doctor,Before two years had sex with a c...   \n\n                                              Doctor  \n0  Hi. I have gone through your query with dilige...  \n1  Hi. You have really done well with the hypothy...  \n2  Hi there Acne has multifactorial etiology. Onl...  \n3  Hello. The popping and discomfort what you fel...  \n4  Hello. The HIV test uses a finger prick blood ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Patient</th>\n      <th>Doctor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q. What does abutment of the nerve root mean?</td>\n      <td>Hi doctor,I am just wondering what is abutting...</td>\n      <td>Hi. I have gone through your query with dilige...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q. What should I do to reduce my weight gained...</td>\n      <td>Hi doctor, I am a 22-year-old female who was d...</td>\n      <td>Hi. You have really done well with the hypothy...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q. I have started to get lots of acne on my fa...</td>\n      <td>Hi doctor! I used to have clear skin but since...</td>\n      <td>Hi there Acne has multifactorial etiology. Onl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q. Why do I have uncomfortable feeling between...</td>\n      <td>Hello doctor,I am having an uncomfortable feel...</td>\n      <td>Hello. The popping and discomfort what you fel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q. My symptoms after intercourse threatns me e...</td>\n      <td>Hello doctor,Before two years had sex with a c...</td>\n      <td>Hello. The HIV test uses a finger prick blood ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Create conversation pairs using Patient and Doctor columns.\ndef create_conversation_pair(row):\n    # We use only the patient input and doctor's response.\n    input_text = \"Patient: \" + row[\"Description\"].strip()\n    target_text = \"Doctor: \" + row[\"Doctor\"].strip()\n    return {\"input_text\": input_text, \"target_text\": target_text}\n\n# Apply the function to each row to create a list of training examples.\nconversation_pairs = df.apply(create_conversation_pair, axis=1).tolist()\ndataset = Dataset.from_list(conversation_pairs)\nprint(\"Number of training examples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:19:10.137856Z","iopub.execute_input":"2025-05-16T14:19:10.138164Z","iopub.status.idle":"2025-05-16T14:19:14.024629Z","shell.execute_reply.started":"2025-05-16T14:19:10.138132Z","shell.execute_reply":"2025-05-16T14:19:14.023747Z"}},"outputs":[{"name":"stdout","text":"Number of training examples: 256916\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Tokenization: Concatenate the input and target, separated by a newline.\nmodel_name = \"microsoft/DialoGPT-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token  # Set pad token\n\ndef tokenize_function(examples):\n    # Each example becomes \"Patient: ...\\nDoctor: ...\"\n    texts = [inp + \"\\n\" + tgt for inp, tgt in zip(examples[\"input_text\"], examples[\"target_text\"])]\n    tokenized = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=512)\n    # For causal language modeling, set the labels equal to input_ids.\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    return tokenized\n\n\n# For example, select 10% of the dataset\nsmall_dataset = dataset.shuffle(seed=42).select(range(int(0.6 * len(dataset))))\ntokenized_dataset = small_dataset.map(tokenize_function, batched=True)\ntokenized_dataset.set_format(\"torch\")\nprint(\"Tokenization complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:19:14.026498Z","iopub.execute_input":"2025-05-16T14:19:14.026764Z","iopub.status.idle":"2025-05-16T14:20:27.351362Z","shell.execute_reply.started":"2025-05-16T14:19:14.026742Z","shell.execute_reply":"2025-05-16T14:20:27.350474Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66ecf3d4ff52432db6b2a189b6cf67b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9fd457a468749b7beb9de11de9c2ea7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0959813ad38846ea81c90382c851e2c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/154149 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7957f250ce1249849273031bf2f379dd"}},"metadata":{}},{"name":"stdout","text":"Tokenization complete.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./fine_tuned_medical_chatbot\",\n    num_train_epochs=1,                # One epoch for a quick run        \n    save_total_limit=2,\n    per_device_train_batch_size=4,\n    evaluation_strategy=\"no\",          # Disable evaluation to save time\n    logging_steps=50,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    report_to=\"none\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n)\n\nprint(\"Starting training...\")\ntrainer.train()\nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:20:27.352718Z","iopub.execute_input":"2025-05-16T14:20:27.353039Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9dc6af214f84be399363aefdc3fbd2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28866802d0a419d8bd52228a21a9500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c5a3af94f24cfc89df37e6e463877b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2969' max='38538' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2969/38538 49:40 < 9:55:29, 1.00 it/s, Epoch 0.08/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.332100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.024300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.957900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.957100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.988300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.899100</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.894100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.828100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.863200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.860200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.809200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.852000</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.770900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.798900</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.812700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.738400</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.785600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.794200</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.788700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.742200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.792800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.816400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.781500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.772500</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.815000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.797000</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.821300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.785600</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.785600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.771200</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.697400</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.782200</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.731300</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.741600</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.717900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.680100</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.754300</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.711500</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.678100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.760500</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.767700</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.786600</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.726000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.732700</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.716100</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.738100</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.708900</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.703200</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.751000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.677400</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.732700</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.681700</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.757700</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.707800</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.713600</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.768900</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.706900</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.721000</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.682600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"trainer.save_model(\"./fine_tuned_medical_chatbot\")\ntokenizer.save_pretrained(\"./fine_tuned_medical_chatbot\")\nprint(\"Model and tokenizer saved.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r fine_tuned_medical_chatbot.zip fine_tuned_medical_chatbot","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install gdow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"curl --upload-file \"/kaggle/working/model_output.zip\" \"https://transfer.sh/model_output.zip\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# INFERENCE\nfrom transformers import pipeline\n# Inference: Load the fine-tuned model using a text-generation pipeline.\nchatbot = pipeline(\n    \"text-generation\",\n    model=\"./fine_tuned_medical_chatbot\",\n    tokenizer=\"./fine_tuned_medical_chatbot\"\n)\n\n# Interactive loop to test the chatbot.\nprint(\"Chatbot is ready. Type 'exit' or 'quit' to stop.\")\nwhile True:\n    user_input = input(\"You: \").strip()\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        break\n    # Format the input to indicate patient dialogue, and prompt the model for a doctor's reply.\n    formatted_input = \"Patient: \" + user_input + \"\\nDoctor:\"\n    response = chatbot(\n        formatted_input,\n        max_length=150,\n        do_sample=True,\n        top_p=0.9,\n        temperature=0.7,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    # Extract doctor's reply by taking the text after \"Doctor:\" if present.\n    generated_text = response[0]['generated_text']\n    if \"Doctor:\" in generated_text:\n        doctor_reply = generated_text.split(\"Doctor:\")[-1].strip()\n    else:\n        doctor_reply = generated_text.strip()\n    print(\"Doctor:\", doctor_reply)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}